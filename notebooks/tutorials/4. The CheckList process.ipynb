{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.expect import Expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read the [paper](https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf), you know that CheckList is more than this package, it's also a process.  \n",
    "This tutorial is a short version of that process, but you should really read the paper if you haven't :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task and Model: QQP, BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this tutorial, we'll use Quora Question Pair as an example, with [a finetuned BERT model hosted by Textattack](https://huggingface.co/textattack/bert-base-uncased-QQP).\n",
    "**Please note that this is not the model reported in the paper -- we finetuned that model locally.** \n",
    "Here, we instead use a model that is available online (loaded through [Huggingface Pipeline](https://huggingface.co/transformers/main_classes/pipelines.html)), so that you can easily follow the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model and spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import spacy\n",
    "import numpy as np\n",
    "processor = spacy.load('en_core_web_sm')\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "model_name = \"textattack/bert-base-uncased-QQP\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# sentiment analysis is a general name in Huggingface to load the pipeline for text classification tasks.\n",
    "# set device=-1 if you don't have a gpu\n",
    "pipe = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, framework=\"pt\", device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset. First, install the [NLP dataset library](https://huggingface.co/nlp/quicktour.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nlp in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (0.4.0)\r\n",
      "Requirement already satisfied: numpy in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from nlp) (2.0.2)\r\n",
      "Requirement already satisfied: pyarrow>=0.16.0 in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from nlp) (18.1.0)\r\n",
      "Requirement already satisfied: dill in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from nlp) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from nlp) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from nlp) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from nlp) (4.67.1)\r\n",
      "Requirement already satisfied: filelock in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from nlp) (3.16.1)\r\n",
      "Requirement already satisfied: xxhash in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from nlp) (3.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from requests>=2.19.0->nlp) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from requests>=2.19.0->nlp) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from requests>=2.19.0->nlp) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from requests>=2.19.0->nlp) (2024.8.30)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from pandas->nlp) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from pandas->nlp) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from pandas->nlp) (2024.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/aaron/miniconda3/envs/checklist/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->nlp) (1.17.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question1': 'Why are African-Americans so beautiful?',\n",
       " 'question2': 'Why are hispanics so beautiful?',\n",
       " 'label': 0,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from nlp import load_dataset\n",
    "# from huggingface_hub import login\n",
    "\n",
    "# login(\"\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "qqp_data = load_dataset('glue', 'qqp', split='validation')\n",
    "all_questions = set()\n",
    "q1s = [d[\"question1\"] for d in qqp_data]\n",
    "q2s = [d[\"question2\"] for d in qqp_data]\n",
    "labels = np.array([d[\"label\"] for d in qqp_data]).astype(int)\n",
    "\n",
    "qs = list(zip(q1s, q2s))\n",
    "qqp_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess all the questions with spacy. This may take sometime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of unique questions: 73324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73324it [00:50, 1451.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "all_questions.update(set(q1s))\n",
    "all_questions.update(set(q2s))\n",
    "print(f\"Total count of unique questions: {len(all_questions)}\")\n",
    "processed_qs = list(tqdm(processor.pipe(all_questions, batch_size=64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_map = {q: processed_q for (q, processed_q) in zip(all_questions, processed_qs)}\n",
    "parsed_qs = [(spacy_map[q[0]], spacy_map[q[1]]) for q in qs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-Down approach: the CheckList matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capabilities x Test Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tutorial #3, we talked about specific test types.  \n",
    "In order to guide test ideation, it's useful to think of CheckList as a matrix of Capabilities x Test Types.  \n",
    "*Capabilities* refers to general-purpose linguistic capabilities, which manifest in one way or another in almost any NLP application.   \n",
    "We suggest that anyone CheckListing a model go through *at least* the following capabilities, trying to create MFTs, INVs, and DIRs for each if possible.\n",
    "1. **Vocabulary + POS:** important words or groups of words (by part-of-speech) for the task\n",
    "2. **Taxonomy**: synonyms, antonyms, word categories, etc\n",
    "3. **Robustness**: to typos, irrelevant additions, contractions, etc\n",
    "4. **Named Entity Recognition (NER)**: person names, locations, numbers, etc\n",
    "5. **Fairness**\n",
    "6. **Temporal understanding**: understanding order of events and how they impact the task\n",
    "7. **Negation**\n",
    "8. **Coreference** \n",
    "9. **Semantic Role Labeling (SRL)**: understanding roles such as agent, object, passive/active, etc\n",
    "10. **Logic**: symmetry, consistency, conjunctions, disjunctions, etc\n",
    "\n",
    "Notice that we are framing this as very top-down approach: you start with a list of capabilities and try to think of what kinds of tests can be created, based on the three test types. We'll talk about how to incorporate some bottom-up thinking later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't try to create tests for **all** of these capabilities (but we do have notebooks with tests for all of them in the repo), just one as an example. \n",
    "Anyway, let's create a test suite (used to save and aggregate tests):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite()\n",
    "editor = Editor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability: NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the NER capability.  \n",
    "How do named entities impact duplicate question detection? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFT\n",
    "It seems that the model should at least be able to distinguish questions about different people as non-duplicates.   \n",
    "Let's write an MFT where we have two people that have the same last name, but different first names.  \n",
    "Instead of running the test now, we'll add it to the suite and run all tests later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Is Mary Marshall lying?', 'Is Lynn Marshall lying?')\n",
      "('Is Don Peterson Jewish?', 'Is Carl Peterson Jewish?')\n"
     ]
    }
   ],
   "source": [
    "t = editor.template((\n",
    "    'Is {first_name} {last_name} {mask}?',\n",
    "    'Is {first_name2} {last_name} {mask}?',\n",
    "    ),\n",
    "    remove_duplicates=True, \n",
    "    nsamples=300)\n",
    "test = MFT(**t, labels=0, name='same adjectives, different people', capability = 'NER',\n",
    "          description='Different first name, same adjective and last name')\n",
    "suite.add(test, overwrite=True)\n",
    "print(t.data[0])\n",
    "print(t.data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INV\n",
    "If you have two questions with the same named entity, changing the entity on both should not change whether the questions are duplicates or not.  \n",
    "Let's write an INV for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with pairs of questions, we have to write a wrapper to make sure the same name is changed on both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_name_on_both(qs):\n",
    "    q1, q2 = qs\n",
    "    c1 = Perturb.change_names(q1, seed=1, meta=True)\n",
    "    c2 = Perturb.change_names(q2, seed=1, meta=True)\n",
    "    if not c1 or not c2:\n",
    "        return\n",
    "    # separating out examples and meta. Meta has tuples (a, b), where name 'a' was changed to 'b'\n",
    "    c1, m1 = c1\n",
    "    c2, m2 = c2\n",
    "    # Only include examples where the same name was changed on both questions\n",
    "    return [(q1, q2) for q1, q2, m1, m2 in zip(c1, c2, m1, m2) if m1 == m2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Who do you think will win, Trump or Hillary?', 'Who is going to win, Trump or Hillary?')\n",
      "('Who do you think will win, Trump or Kayla?', 'Who is going to win, Trump or Kayla?')\n",
      "('Who do you think will win, Trump or Kimberly?', 'Who is going to win, Trump or Kimberly?')\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(parsed_qs, change_name_on_both, nsamples=200)\n",
    "test = INV(**t, name='Change same name in both questions', capability='NER',\n",
    "          description='')\n",
    "# test.run(new_pp)\n",
    "# test.summary(3)\n",
    "suite.add(test, overwrite=True)\n",
    "print(t.data[0][0])\n",
    "print(t.data[0][1])\n",
    "print(t.data[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIR\n",
    "Conversely, if an entity is present on a pair the model predicts as a duplicate and we change it to something else on *only one* of the sentences, the prediction should change to non-duplicate.  \n",
    "Let's write this as a DIR test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_name_on_one(qs):\n",
    "    q1, q2 = qs\n",
    "    c1 = Perturb.change_names(q1, seed=1, meta=True)\n",
    "    c2 = Perturb.change_names(q2, seed=1, meta=True)\n",
    "    if not c1 or not c2:\n",
    "        return\n",
    "    c1, m1 = c1\n",
    "    c2, m2 = c2\n",
    "    ret = []\n",
    "    ret.extend([(q1_, str(q2)) for q1_, m1_ in zip(c1, m1) if m1_[0] in str(q2)])\n",
    "    ret.extend([(str(q1), q2_) for q2_, m2_ in zip(c2, m2) if m2_[0] in str(q1)])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write an expectation function in two steps.  \n",
    "First, we want the prediction to be 0.  \n",
    "Second, we only want to include examples where the original prediction is one. We do this with a slice wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_fn = Expect.eq(0)\n",
    "expect_fn = Expect.slice_orig(expect_fn, lambda orig, *args: orig == 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it all together into a test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How was the personal relationship between Steve Jobs and Bill Gates?', 'Did Steve Jobs hate Bill Gates?')\n",
      "('How was the personal relationship between Steve Jobs and Michael Brooks?', 'Did Steve Jobs hate Bill Gates?')\n",
      "('How was the personal relationship between Steve Jobs and Christopher Cox?', 'Did Steve Jobs hate Bill Gates?')\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(parsed_qs, change_name_on_one, nsamples=200)\n",
    "name = 'Change name in one of the questions'\n",
    "desc = 'Take pairs that are originally predicted as duplicates, change name in one of them and expect new prediction to be non-duplicate'\n",
    "test = DIR(**t, expect=expect_fn, name=name, description=desc, capability='NER')\n",
    "suite.add(test, overwrite=True)\n",
    "print(t.data[0][0])\n",
    "print(t.data[0][1])\n",
    "print(t.data[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples illustrate how thinking through the matrix can help test ideation. We now turn to a bottom up approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottom up approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we look at specific examples (from the validation dataset or elsewhere) and try to generalize them into MFTs, INVs or DIRs, placing them into a specific capability.  \n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Which company should I join as a fresher, TCS or Virtusa?',\n",
       " 'Is it a good decision to join Tcs as a fresher?')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(14)\n",
    "i = np.random.choice(len(qs))\n",
    "qs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good example, in which a question asks about a comparison between two options, while the other question asks about a single option.  \n",
    "While they are not duplicates, it is possible that models would get confused here. I think this test fits into the Vocabulary+POS capability (it's not crucial for us to be completely precise about where a test fits).  \n",
    "Let's try to create an MFT out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple, Google, Facebook, This, Microsoft, Amazon, Uber, It, Intel, Samsung, Netflix, Tesla, Twitter, LinkedIn, Oracle, Snap, Target, Disney, AMD, Bloomberg, Sony, That, Wikipedia, China, Fox, Here, this, FB, YouTube, HP, Reddit, Ford, Harris, Pinterest, MIT, GE, Dialog, Square, CBS, Orange'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(editor.suggest('{mask} is a large tech company.')[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['Apple', 'Google', 'Facebook', 'Microsoft', 'Amazon', 'Uber', 'Intel', 'Samsung', 'Netflix', 'Tesla', 'LinkedIn', 'Oracle', 'Target', 'Snap', 'Disney', 'AMD', 'Sony', 'Reddit', 'Youtube']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'customer, shareholder, member, developer, volunteer, competitor, contributor, contractor, professional, student, buyer, writer, rookie, manager, consumer, worker, pro, teenager, client, sponsor, subscriber, consultant, CEO, user, Beta, director, beta, researcher, citizen, result'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(editor.suggest('Should I join {company} as a {mask}?', company=companies)[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = ['developer', 'contributor', 'freshman', 'college grad', 'volunteer', 'writer', 'contractor', 'consultant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Which company should I join as a contributor, Facebook or Samsung?', 'Should I join Facebook as a contributor?')\n",
      "('Which company should I join as a volunteer, Sony or LinkedIn?', 'Should I join Sony as a volunteer?')\n",
      "('Which company should I join as a consultant, Apple or Disney?', 'Should I join Apple as a consultant?')\n"
     ]
    }
   ],
   "source": [
    "t = editor.template((\n",
    "       'Which company should I join as a {role}, {company1} or {company2}?',\n",
    "       'Should I join {company1} as a {role}?',\n",
    "   ),\n",
    "    company=companies,\n",
    "    role=role,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    ")\n",
    "print(t.data[0])\n",
    "print(t.data[1])\n",
    "print(t.data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've replicated the original example, but we can generalize it a bit to other comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('dominance', 'continue'), ('strategy', 'work'), ('efforts', 'succeed'), ('success', 'continue'), ('experiment', 'work'), ('dominance', 'last'), ('experiment', 'succeed'), ('dominance', 'end'), ('strategy', 'succeed'), ('efforts', 'work'), ('plan', 'work'), ('woes', 'continue'), ('growth', 'continue'), ('strategy', 'stick'), ('gamble', 'succeed'), ('approach', 'work'), ('dominance', 'endure'), ('failures', 'continue'), ('tactics', 'work'), ('experiments', 'work'), ('decision', 'stick'), ('success', 'last'), ('domination', 'continue'), ('lawsuit', 'succeed'), ('gamble', 'work'), ('push', 'succeed'), ('behavior', 'change'), ('ambitions', 'succeed'), ('dominance', 'fade'), ('dominance', 'persist'), ('strategy', 'change'), ('experiments', 'succeed'), ('dominance', 'return'), ('problems', 'continue'), ('policies', 'change'), ('scandals', 'continue'), ('strategy', 'continue'), ('plan', 'succeed'), ('focus', 'change'), ('dominance', 'survive'), ('takeover', 'succeed'), ('move', 'work'), ('mission', 'succeed'), ('practices', 'continue'), ('efforts', 'continue'), ('failure', 'continue'), ('crackdown', 'work'), ('ambitions', 'continue'), ('acquisitions', 'continue'), ('push', 'work')\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join([str(x) for x in editor.suggest('Will Google\\'s {mask} {mask}?')][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Which company's board will resign most, Microsoft or Apple?\", \"Will Microsoft's board resign?\")\n",
      "(\"Which company's board will resign most, LinkedIn or Youtube?\", \"Will LinkedIn's board resign?\")\n",
      "(\"Which company's CEO will quit sooner, Youtube or Amazon?\", \"Will Youtube's CEO quit?\")\n"
     ]
    }
   ],
   "source": [
    "t += editor.template((\n",
    "       'Which company\\'s {fverb[0]} will {fverb[1]} {comp}, {company1} or {company2}?',\n",
    "       'Will {company1}\\'s {fverb[0]} {fverb[1]}?',\n",
    "   ),\n",
    "    company=companies,\n",
    "    comp=['most', 'least', 'sooner', 'later'],\n",
    "    fverb=[('stock', 'rise'), ('CEO', 'quit'), ('board', 'resign'), ('stock', 'fall'), ('effort', 'succeed'), ('strategy', 'work'), ('plan', 'work'), ('gamble', 'work'), ('focus', 'change'), ('intentions', 'change')],\n",
    "    nsamples=300,\n",
    "    remove_duplicates=True,\n",
    ")\n",
    "print(t.data[-1])\n",
    "print(t.data[-2])\n",
    "print(t.data[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MFT(**t, labels=0, name='Comparison between two entities is not the same as asking about one', capability = 'Vocabulary',\n",
    "          description='')\n",
    "suite.add(test, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the suite, seeing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the prediction, the Huggingface pipeline returns a dict with predicted label and probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9998934268951416}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ('Which company should I join as a freshman, Google or Facebook?', 'Should I join Google as a freshman?')\n",
    "pipe([example], truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a simple wrapper to make the output compatible with CheckList:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_conf(data):\n",
    "    raw_preds = pipe(data, padding=True, truncation=True)\n",
    "    preds = np.array([ int(p[\"label\"][-1]) for p in raw_preds])\n",
    "    pp = np.array([[p[\"score\"], 1-p[\"score\"]] if int(p[\"label\"][-1]) == 0 else [1-p[\"score\"], p[\"score\"]] for p in raw_preds])\n",
    "    return preds, pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running same adjectives, different people\n",
      "Predicting 299 examples\n",
      "Running Change same name in both questions\n",
      "Predicting 2065 examples\n",
      "Running Change name in one of the questions\n",
      "Predicting 3876 examples\n",
      "Running Comparison between two entities is not the same as asking about one\n",
      "Predicting 946 examples\n",
      "Running How can I become more {synonym}?\n",
      "Predicting 200 examples\n",
      "Running How can I become more X = How can I become less antonym(X)\n",
      "Predicting 600 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(pred_and_conf, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a (text) summary of the results by calling `suite.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Comparison between two entities is not the same as asking about one\n",
      "Test cases:      946\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taxonomy\n",
      "\n",
      "How can I become more {synonym}?\n",
      "Test cases:      200\n",
      "Fails (rate):    200 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.0 ('How can I become more angry?', 'How can I become more furious?')\n",
      "----\n",
      "0.0 ('How can I become less organized?', 'How can I become less organised?')\n",
      "----\n",
      "0.0 ('How can I become less intelligent?', 'How can I become less smart?')\n",
      "----\n",
      "\n",
      "\n",
      "How can I become more X = How can I become less antonym(X)\n",
      "Test cases:      600\n",
      "Fails (rate):    600 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.0 ('How can I become less progressive?', 'How can I become more conservative?')\n",
      "----\n",
      "0.0 ('How can I become less humble?', 'How can I become more proud?')\n",
      "----\n",
      "0.0 ('How can I become less stupid?', 'How can I become more smart?')\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "same adjectives, different people\n",
      "Test cases:      299\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Change same name in both questions\n",
      "Test cases:      200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Change name in one of the questions\n",
      "Test cases:      200\n",
      "After filtering: 0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we're using jupyter, we can use a nifty visualization that has all of the tests we created in a matrix.  \n",
    "You can navigate the matrix and see results for individual tests (*The screenshot below is based on our locally finetuned model, so the numbers may not match with your results.*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e636264f0b45868ef1a2e3a794d81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'same adjectives, difâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from IPython.display import HTML, Image\n",
    "# with open('visual_table_summary.gif','rb') as f:\n",
    "#     display(Image(data=f.read(), format='png'))\n",
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: testing Taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a few additional tests for the Taxonomy capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('addicted', 'addict'), ('organised', 'organized', 'direct', 'engineer'), ('capable', 'open', 'able'), ('worried', 'upset'), ('religious', 'spiritual'), ('conservative', 'cautious'), ('effective', 'efficient'), ('bad', 'spoiled', 'sorry', 'risky', 'tough', 'defective'), ('inspired', 'divine'), ('desperate', 'heroic'), ('strict', 'rigid', 'stern'), ('stressed', 'distressed', 'stress'), ('intimidating', 'daunting'), ('ethical', 'honorable'), ('positive', 'confident'), ('educated', 'enlightened'), ('miserable', 'poor', 'suffering', 'low', 'pathetic', 'wretched'), ('evil', 'vicious'), ('alone', 'lonely', 'solitary'), ('nervous', 'anxious'), ('understanding', 'savvy'), ('organized', 'organised', 'direct'), ('hungry', 'thirsty'), ('important', 'authoritative', 'significant'), ('lonely', 'alone', 'solitary'), ('obnoxious', 'objectionable'), ('enlightened', 'educated', 'clear'), ('anxious', 'nervous'), ('independent', 'autonomous'), ('sensitive', 'sensible'), ('authoritarian', 'dictator'), ('frustrated', 'queer'), ('hateful', 'mean'), ('thoughtful', 'attentive'), ('critical', 'decisive', 'vital'), ('disruptive', 'troubled'), ('active', 'alive', 'dynamic'), ('vain', 'futile'), ('mindful', 'aware'), ('healthy', 'intelligent', 'sound'), ('so', 'then'), ('charitable', 'benevolent', 'sympathetic'), ('cautious', 'conservative', 'timid'), ('consistent', 'uniform', 'logical', 'coherent'), ('knowledgeable', 'learned', 'intimate', 'knowing'), ('alienated', 'alien', 'estranged'), ('fat', 'productive', 'rich', 'fatty'), ('militant', 'activist', 'competitive'), ('committed', 'attached'), ('needy', 'impoverished')\n"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "x = editor.suggest('How can I become more {mask}?')\n",
    "x += editor.suggest('How can I become less {mask}?')\n",
    "for a in set(x):\n",
    "    e = editor.synonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less'])\n",
    "    if e:\n",
    "#         print(a, [b[0][0] for b in e] )\n",
    "        tmp.append([a] + e)\n",
    "#         opps.append((a, e[0][0][0]))\n",
    "print(', '.join([str(tuple(x)) for x in tmp][:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all of those, let's pick a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = [ ('spiritual', 'religious'), ('angry', 'furious'), ('organized', 'organised'),\n",
    "            ('vocal', 'outspoken'), ('grateful', 'thankful'), ('intelligent', 'smart'),\n",
    "            ('humble', 'modest'), ('courageous', 'brave'), ('happy', 'joyful'), ('scared', 'frightened'),\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these, we can create a simple MFT, where we expect the model to recognize these synonyms.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template(\n",
    "    (\n",
    "    'How can I become {moreless} {x[0]}?',\n",
    "    'How can I become {moreless} {x[1]}?',\n",
    "    ),\n",
    "    x=synonyms,\n",
    "    moreless=['more', 'less'],\n",
    "    remove_duplicates=True, \n",
    "    nsamples=200)\n",
    "name = 'How can I become more {synonym}?' \n",
    "desc = 'different (simple) templates where words are replaced with their synonyms'\n",
    "test = MFT(**t, labels=1, name=name, capability = 'Taxonomy',\n",
    "          description=desc)\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with antonyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conservative', 'progressive', 'liberal'),('bad', 'good'),('pessimistic', 'optimistic'),('positive', 'negative'),('organic', 'functional'),('impatient', 'patient'),('hungry', 'thirsty'),('active', 'passive'),('optimistic', 'pessimistic'),('invisible', 'visible'),('negative', 'positive'),('cautious', 'brave'),('fat', 'lean', 'thin'),('relevant', 'irrelevant'),('powerless', 'powerful'),('corrupt', 'straight'),('rude', 'civil', 'polite'),('stupid', 'intelligent', 'smart'),('specific', 'general'),('unhappy', 'happy'),('emotional', 'intellectual'),('visible', 'invisible'),('passive', 'active'),('insecure', 'secure'),('progressive', 'conservative'),('courageous', 'fearful'),('individual', 'common'),('dependent', 'independent'),('shy', 'confident'),('uncomfortable', 'comfortable'),('defensive', 'offensive'),('humble', 'proud'),('hopeful', 'hopeless'),('conspicuous', 'invisible'),('irresponsible', 'responsible')\n"
     ]
    }
   ],
   "source": [
    "opps = []\n",
    "x = editor.suggest('How can I become more {mask}?')\n",
    "x += editor.suggest('How can I become less {mask}?')\n",
    "for a in set(x):\n",
    "    e = editor.antonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less'])\n",
    "    if e:\n",
    "#         print(a, [b[0][0] for b in e] )\n",
    "        opps.append([a] + e)\n",
    "#         opps.append((a, e[0][0][0]))\n",
    "print(','.join([str(tuple(x)) for x in opps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "antonyms = [('progressive', 'conservative'),('religious', 'secular'),('positive', 'negative'),('defensive', 'offensive'),('rude',  'polite'),('optimistic', 'pessimistic'),('stupid', 'smart'),('negative', 'positive'),('unhappy', 'happy'),('active', 'passive'),('impatient', 'patient'),('powerless', 'powerful'),('visible', 'invisible'),('fat', 'thin'),('bad', 'good'),('cautious', 'brave'), ('hopeful', 'hopeless'),('insecure', 'secure'),('humble', 'proud'),('passive', 'active'),('dependent', 'independent'),('pessimistic', 'optimistic'),('irresponsible', 'responsible'),('courageous', 'fearful')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template([(\n",
    "    'How can I become more {x[0]}?',\n",
    "    'How can I become less {x[1]}?',\n",
    "    ),\n",
    "    (\n",
    "    'How can I become less {x[0]}?',\n",
    "    'How can I become more {x[1]}?',\n",
    "    )],\n",
    "    unroll=True,\n",
    "    x=antonyms,\n",
    "    remove_duplicates=True, \n",
    "    nsamples=300)\n",
    "name = 'How can I become more X = How can I become less antonym(X)' \n",
    "desc = ''\n",
    "test = MFT(**t, labels=1, name=name, capability = 'Taxonomy',\n",
    "          description=desc)\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be easy to turn the synonym one into an INV as well (we do this in another notebook), but let's end here after we run the suite again and see new results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running same adjectives, different people\n",
      "Predicting 299 examples\n",
      "Running Change same name in both questions\n",
      "Predicting 2065 examples\n",
      "Running Change name in one of the questions\n",
      "Predicting 3876 examples\n",
      "Running Comparison between two entities is not the same as asking about one\n",
      "Predicting 946 examples\n",
      "Running How can I become more {synonym}?\n",
      "Predicting 200 examples\n",
      "Running How can I become more X = How can I become less antonym(X)\n",
      "Predicting 600 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(pred_and_conf, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Comparison between two entities is not the same as asking about one\n",
      "Test cases:      946\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taxonomy\n",
      "\n",
      "How can I become more {synonym}?\n",
      "Test cases:      200\n",
      "Fails (rate):    200 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.0 ('How can I become more angry?', 'How can I become more furious?')\n",
      "----\n",
      "0.0 ('How can I become less happy?', 'How can I become less joyful?')\n",
      "----\n",
      "0.0 ('How can I become more scared?', 'How can I become more frightened?')\n",
      "----\n",
      "\n",
      "\n",
      "How can I become more X = How can I become less antonym(X)\n",
      "Test cases:      600\n",
      "Fails (rate):    600 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.0 ('How can I become more progressive?', 'How can I become less conservative?')\n",
      "----\n",
      "0.0 ('How can I become less stupid?', 'How can I become more smart?')\n",
      "----\n",
      "0.0 ('How can I become less hopeful?', 'How can I become more hopeless?')\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "same adjectives, different people\n",
      "Test cases:      299\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Change same name in both questions\n",
      "Test cases:      200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Change name in one of the questions\n",
      "Test cases:      200\n",
      "After filtering: 0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suite.visual_summary_table()\n",
    "suite.save('./test.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running same adjectives, different people\n",
      "Predicting 299 examples\n",
      "Running Change same name in both questions\n",
      "Predicting 2065 examples\n",
      "Running Change name in one of the questions\n",
      "Predicting 3876 examples\n",
      "Running Comparison between two entities is not the same as asking about one\n",
      "Predicting 946 examples\n",
      "Running How can I become more {synonym}?\n",
      "Predicting 200 examples\n",
      "Running How can I become more X = How can I become less antonym(X)\n",
      "Predicting 600 examples\n",
      "Vocabulary\n",
      "\n",
      "Comparison between two entities is not the same as asking about one\n",
      "Test cases:      946\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taxonomy\n",
      "\n",
      "How can I become more {synonym}?\n",
      "Test cases:      200\n",
      "Fails (rate):    200 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.0 ('How can I become more vocal?', 'How can I become more outspoken?')\n",
      "----\n",
      "0.0 ('How can I become more organized?', 'How can I become more organised?')\n",
      "----\n",
      "0.0 ('How can I become less courageous?', 'How can I become less brave?')\n",
      "----\n",
      "\n",
      "\n",
      "How can I become more X = How can I become less antonym(X)\n",
      "Test cases:      600\n",
      "Fails (rate):    600 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.0 ('How can I become less positive?', 'How can I become more negative?')\n",
      "----\n",
      "0.0 ('How can I become more unhappy?', 'How can I become less happy?')\n",
      "----\n",
      "0.0 ('How can I become more humble?', 'How can I become less proud?')\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "same adjectives, different people\n",
      "Test cases:      299\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Change same name in both questions\n",
      "Test cases:      200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Change name in one of the questions\n",
      "Test cases:      200\n",
      "After filtering: 0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite_path = './test.pkl'\n",
    "test_suite = TestSuite.from_file(suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True)\n",
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
